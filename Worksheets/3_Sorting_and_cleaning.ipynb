{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/futureCodersSE/python-programming-for-data/blob/main/Worksheets/3_Sorting_and_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CVoh0pMzW0l"
      },
      "source": [
        "# Sorting and cleaning \n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "In order to effectively analyse a dataset, often we need to prepare it first. \n",
        "Before a dataset is ready to be analysed we might need to:  \n",
        "\n",
        "* sort the data (can be a series or dataframe)  \n",
        "* remove any NaN values or drop NA values   \n",
        "* remove duplicate records (identical rows)  \n",
        "* normalise data in dataframe columns so that has a common scale [reference](https://towardsai.net/p/data-science/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff#:~:text=Similarly%2C%20the%20goal%20of%20normalization,dataset%20does%20not%20require%20normalization.&text=So%20we%20normalize%20the%20data,variables%20to%20the%20same%20range.)\n",
        "\n",
        "## Sorting the data  \n",
        "---\n",
        "\n",
        "\n",
        "Typically we want to sort data by the values in one or more columns in the dataframe  \n",
        "\n",
        "To sort the dataframe by series we use the pandas function **sort_values()**.  \n",
        "\n",
        "By default `sort_values()` sorts into ascending order.\n",
        "\n",
        "* sort by a single column e.g.\n",
        "  * `df.sort_values(\"Make\") `\n",
        "* sort by multiple columns e.g. \n",
        "  * `df.sort_values(by = [\"Model\", \"Make\"]) `\n",
        "    * this sorts by Model, then my Make \n",
        "* sort in *descending* order\n",
        "  * `df.sort_values(by = \"Make\", ascending = False)`\n",
        "  * `df.sort_values(by = [\"Make\", \"Model\"], ascending = False])`  \n",
        "\n",
        "Dataframes are mostly **immutable**, ie changes like sort_values do not change the dataframe permanently, they just change it for the time that the instruction is being used.\n",
        "\n",
        "`df.sort_values(by='Make')` *dataframe is now in sorted order and can be copied to a new dataframe*  \n",
        "`df_sorted_on_make` *original dataframe, df, will be as it was - unsorted* \n",
        "\n",
        "To **split** columns away from the dataframe after sorting, do this in the same instruction, e.g.:\n",
        "\n",
        "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]]`\n",
        "\n",
        "This sorts on Make and then Model in descending order, then splits off the Make and Model columns.\n",
        "\n",
        "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]].head()`\n",
        "\n",
        "This sorts on Make and then Model, then splits off the Make and Model columns and then splits off the first 5 rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANKknIx8E-hN"
      },
      "source": [
        "### Exercise 1 - get data, sort by happiness score \n",
        "---\n",
        "\n",
        "Read data into variable called **happiness** from the Excel file on Happiness Data at this link: https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\n",
        "\n",
        "Write a function called **sorted_rank** to display first 5 rows of data  \n",
        "\n",
        "The data is currently sorted by Happiness Rank...\n",
        "*  sort the data by Happiness Score in ascending order\n",
        "*  display sorted table\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jkvFGvJtHXiH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Well done, test passed\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true'\n",
        "happiness =  pd.read_excel(url)\n",
        "\n",
        "\n",
        "def sorted_rank(df):\n",
        "  return happiness.sort_values(by=['Happiness Score'], ascending=True)\n",
        "\n",
        "\n",
        "\n",
        "# The code below will run and test your code to see if the first row of your series is correct \n",
        "actual = sorted_rank(happiness).index[0]\n",
        "expected = 157\n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Well done, test passed\")\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_iomqRTH8LA"
      },
      "source": [
        "### Exercise 2 - sort by multiple columns, display the first 5 rows \n",
        "---\n",
        "\n",
        "Write a function called **get_gdp_health** which:\n",
        "\n",
        "1. sort the data by Economy (GDP per Capita) and Health (Life Expectancy) in ascending order \n",
        "2. display the first 5 rows of sorted data \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "b7XalX7OK0u-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Well done, test passed\n"
          ]
        }
      ],
      "source": [
        "def get_gdp_health():\n",
        "  return happiness.sort_values(by=['Economy (GDP per Capita)', 'Health (Life Expectancy)']).head(5)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# The code below will run and test your code to see if the first row of your series has the correct happiness score \n",
        "test = get_gdp_health()\n",
        "\n",
        "actual = test['Happiness Score'].iloc[0]\n",
        "expected = 4.517\n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Well done, test passed\")\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfQ3cys4LHNc"
      },
      "source": [
        "### Exercise 3 - sorting in descending order \n",
        "---\n",
        "\n",
        "Write a function called **get_descending** which will: \n",
        "\n",
        "Sort the data by Freedom and Trust (Government Corruption) in descending order and show the Country and Region only for the last five rows\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country</th>\n",
              "      <th>Region</th>\n",
              "      <th>Happiness Rank</th>\n",
              "      <th>Happiness Score</th>\n",
              "      <th>Standard Error</th>\n",
              "      <th>Economy (GDP per Capita)</th>\n",
              "      <th>Family</th>\n",
              "      <th>Health (Life Expectancy)</th>\n",
              "      <th>Freedom</th>\n",
              "      <th>Trust (Government Corruption)</th>\n",
              "      <th>Generosity</th>\n",
              "      <th>Dystopia Residual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Uzbekistan</td>\n",
              "      <td>Central and Eastern Europe</td>\n",
              "      <td>44.0</td>\n",
              "      <td>6.003</td>\n",
              "      <td>0.04361</td>\n",
              "      <td>0.63244</td>\n",
              "      <td>1.34043</td>\n",
              "      <td>0.59772</td>\n",
              "      <td>0.65821</td>\n",
              "      <td>0.30826</td>\n",
              "      <td>0.22837</td>\n",
              "      <td>2.23741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Sweden</td>\n",
              "      <td>Western Europe</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.364</td>\n",
              "      <td>0.03157</td>\n",
              "      <td>1.33171</td>\n",
              "      <td>1.28907</td>\n",
              "      <td>0.91087</td>\n",
              "      <td>0.65980</td>\n",
              "      <td>0.43844</td>\n",
              "      <td>0.36262</td>\n",
              "      <td>2.37119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>Cambodia</td>\n",
              "      <td>Southeastern Asia</td>\n",
              "      <td>145.0</td>\n",
              "      <td>3.819</td>\n",
              "      <td>0.05069</td>\n",
              "      <td>0.46038</td>\n",
              "      <td>0.62736</td>\n",
              "      <td>0.61114</td>\n",
              "      <td>0.66246</td>\n",
              "      <td>0.07247</td>\n",
              "      <td>0.40359</td>\n",
              "      <td>0.98195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Switzerland</td>\n",
              "      <td>Western Europe</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.587</td>\n",
              "      <td>0.03411</td>\n",
              "      <td>1.39651</td>\n",
              "      <td>1.34951</td>\n",
              "      <td>0.94143</td>\n",
              "      <td>0.66557</td>\n",
              "      <td>0.41978</td>\n",
              "      <td>0.29678</td>\n",
              "      <td>2.51738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Norway</td>\n",
              "      <td>Western Europe</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.522</td>\n",
              "      <td>0.03880</td>\n",
              "      <td>1.45900</td>\n",
              "      <td>1.33095</td>\n",
              "      <td>0.88521</td>\n",
              "      <td>0.66973</td>\n",
              "      <td>0.36503</td>\n",
              "      <td>0.34699</td>\n",
              "      <td>2.46531</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Country                      Region  Happiness Rank  Happiness Score  \\\n",
              "43    Uzbekistan  Central and Eastern Europe            44.0            6.003   \n",
              "7         Sweden              Western Europe             8.0            7.364   \n",
              "144     Cambodia           Southeastern Asia           145.0            3.819   \n",
              "0    Switzerland              Western Europe             1.0            7.587   \n",
              "3         Norway              Western Europe             4.0            7.522   \n",
              "\n",
              "     Standard Error  Economy (GDP per Capita)   Family  \\\n",
              "43          0.04361                   0.63244  1.34043   \n",
              "7           0.03157                   1.33171  1.28907   \n",
              "144         0.05069                   0.46038  0.62736   \n",
              "0           0.03411                   1.39651  1.34951   \n",
              "3           0.03880                   1.45900  1.33095   \n",
              "\n",
              "     Health (Life Expectancy)  Freedom  Trust (Government Corruption)  \\\n",
              "43                    0.59772  0.65821                        0.30826   \n",
              "7                     0.91087  0.65980                        0.43844   \n",
              "144                   0.61114  0.66246                        0.07247   \n",
              "0                     0.94143  0.66557                        0.41978   \n",
              "3                     0.88521  0.66973                        0.36503   \n",
              "\n",
              "     Generosity  Dystopia Residual  \n",
              "43      0.22837            2.23741  \n",
              "7       0.36262            2.37119  \n",
              "144     0.40359            0.98195  \n",
              "0       0.29678            2.51738  \n",
              "3       0.34699            2.46531  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3haPVvX7MCom"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test passed 136\n"
          ]
        }
      ],
      "source": [
        "def get_descending(df):\n",
        "  return  happiness.sort_values(by=['Freedom', 'Trust (Government Corruption)'], ascending=False).tail(5)\n",
        "\n",
        "\n",
        "# The code below will run and test your code to see if the length and series are correct \n",
        "actual = get_descending(happiness).index[0]\n",
        "expected = 136\n",
        "\n",
        "if actual == expected and (len(get_descending(happiness)) == 5):\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual, \"and length of series should have been 5 but was\", len(get_descending(happiness)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqnAoELjMDs7"
      },
      "source": [
        "# Cleaning the data\n",
        "\n",
        "Data comes from a range of sources:  forms, monitoring devices, etc.  There will often be missing values, duplicate records and values that are incorrectly formatted.  These can affect summary statistics and graphs plotted from the data.\n",
        "\n",
        "Techniques for data cleansing include:\n",
        "*  removing records with missing or null data (NaN, NA, \"\")\n",
        "*  removing duplicate rows (keeping just one, either the first or the last)\n",
        "\n",
        "Removal of rows according to criteria, or of columns are other ways that data might be cleaned up.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVqmfM5wk7NK"
      },
      "source": [
        "---\n",
        "\n",
        "## Removing NaN/Dropping NA values \n",
        "\n",
        "pandas have functions for checking a dataframe, or column, for null values, checking a column for missing values, and functions for dropping all rows that contain null values.\n",
        "\n",
        "* check for NA/NaN/missing values across dataframe (returns True if NA values exist)  \n",
        "  `df.isnull().values.any()`  \n",
        "\n",
        "* check for NA/NaN/missing values in specific column  \n",
        "  `df[\"column\"].isnull().values.any()`  \n",
        "\n",
        "* filter for non-null rows   \n",
        "  `df[~df[\"column\"].isnull()]`  \n",
        "  *hint: ~ means is not*\n",
        "\n",
        "* drop all rows that have NA/NaN values   \n",
        "  `df.dropna()`  \n",
        "\n",
        "* drop rows where NA/NaN values exist in specific columns  \n",
        "  `df.dropna(subset = [\"Make\", \"Model\"])`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC65hEZGOKNL"
      },
      "source": [
        "### Exercise 4 - check for null values \n",
        "---\n",
        "\n",
        "1. read data into a variable called **housing** from the file housing_in_london_yearly_variables.csv from this link: https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv \n",
        "\n",
        "Write a function called **check_null** which will:\n",
        "2. check if any NA values exist in the dataframe and print the result \n",
        "3. use df.info() to see which columns have null entries (*Hint: if the non-null count is less than total entries, column contains missing/NA entries*)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "url = r'https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv'\n",
        "housing = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "U7LYkXDNVVc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test passed True\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1071 entries, 0 to 1070\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   code               1071 non-null   object \n",
            " 1   area               1071 non-null   object \n",
            " 2   date               1071 non-null   object \n",
            " 3   median_salary      1049 non-null   float64\n",
            " 4   life_satisfaction  352 non-null    float64\n",
            " 5   mean_salary        1071 non-null   object \n",
            " 6   recycling_pct      860 non-null    object \n",
            " 7   population_size    1018 non-null   float64\n",
            " 8   number_of_jobs     931 non-null    float64\n",
            " 9   area_size          666 non-null    float64\n",
            " 10  no_of_houses       666 non-null    float64\n",
            " 11  borough_flag       1071 non-null   int64  \n",
            "dtypes: float64(6), int64(1), object(5)\n",
            "memory usage: 100.5+ KB\n"
          ]
        }
      ],
      "source": [
        "def check_null(df):\n",
        "  return housing.isnull().any().any()\n",
        "\n",
        " \n",
        "\n",
        "# The code below will run and test your code to see if you are returning the correct answer\n",
        "actual = check_null(housing)\n",
        "expected = True\n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual)\n",
        "\n",
        "housing.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJTecutIXFJM"
      },
      "source": [
        "### Exercise 5 - filter for non-null rows\n",
        "---\n",
        "\n",
        "Create function called **filter_null()** which filters the non-null rows by the `number_of_jobs` column. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "7fWi0_MLXEzY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test passed 931\n"
          ]
        }
      ],
      "source": [
        "def filter_null(df):\n",
        "  return housing[~housing['number_of_jobs'].isnull()]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# The code below will run and test your code to see if the length of your returned dataframe is correct\n",
        "\n",
        "actual = len(filter_null(housing))\n",
        "expected = 931 \n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed expected\", expected, \"got\", actual)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRBLm_bJVItu"
      },
      "source": [
        "### Exercise 5 - remove null values \n",
        "---\n",
        "Write a function called **drop_null** which will:\n",
        "1. remove rows with NA values for `life_satisfaction` (use [ ] even if only one column in list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "OjZJNIC3QObK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test passed 613\n"
          ]
        }
      ],
      "source": [
        "def drop_null(df):\n",
        "  return housing.dropna(subset=['life_satisfaction'])\n",
        "  \n",
        "\n",
        "\n",
        "# The code below will run and test your code to see if you have returned a series with the correct length and first row\n",
        "actual = drop_null(housing).index[0]\n",
        "expected = 613 \n",
        "\n",
        "if actual == expected and len(drop_null(housing)) == 352:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual, \"and length of series should have been 352 but was\", len(drop_null(housing))) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui8HF5z8SiK8"
      },
      "source": [
        "## Dropping duplicates\n",
        "---\n",
        "\n",
        "* To remove duplicate rows based on duplication of values in all columns  \n",
        "  `df.drop_duplicates()`  \n",
        "\n",
        "* To remove rows that have duplicate entries in a specified column  \n",
        "  `df.drop_duplicates(subset = ['Make'])`  \n",
        "\n",
        "* To remove rows that have duplicate entries in multiple columns  \n",
        "  `df.drop_duplicates(subset = ['Make', 'Model'])` \n",
        "\n",
        "* Remove duplicate rows keeping the last instance rather than the first (default):  \n",
        "  `df.drop_duplicates(keep='last')`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2Qf6uMxSb5t"
      },
      "source": [
        "### Exercise 6 - Removing duplicate entries \n",
        "---\n",
        "Write a function called **drop_duplicates** which will: \n",
        "\n",
        "remove duplicate `area` entries keeping first instance  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>area</th>\n",
              "      <th>date</th>\n",
              "      <th>median_salary</th>\n",
              "      <th>life_satisfaction</th>\n",
              "      <th>mean_salary</th>\n",
              "      <th>recycling_pct</th>\n",
              "      <th>population_size</th>\n",
              "      <th>number_of_jobs</th>\n",
              "      <th>area_size</th>\n",
              "      <th>no_of_houses</th>\n",
              "      <th>borough_flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>E09000001</td>\n",
              "      <td>city of london</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>33020.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>48922</td>\n",
              "      <td>0</td>\n",
              "      <td>6581.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>E09000002</td>\n",
              "      <td>barking and dagenham</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>21480.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23620</td>\n",
              "      <td>3</td>\n",
              "      <td>162444.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>E09000003</td>\n",
              "      <td>barnet</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>19568.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23128</td>\n",
              "      <td>8</td>\n",
              "      <td>313469.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>E09000004</td>\n",
              "      <td>bexley</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>18621.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21386</td>\n",
              "      <td>18</td>\n",
              "      <td>217458.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>E09000005</td>\n",
              "      <td>brent</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>18532.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20911</td>\n",
              "      <td>6</td>\n",
              "      <td>260317.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        code                  area        date  median_salary  \\\n",
              "0  E09000001        city of london  1999-12-01        33020.0   \n",
              "1  E09000002  barking and dagenham  1999-12-01        21480.0   \n",
              "2  E09000003                barnet  1999-12-01        19568.0   \n",
              "3  E09000004                bexley  1999-12-01        18621.0   \n",
              "4  E09000005                 brent  1999-12-01        18532.0   \n",
              "\n",
              "   life_satisfaction mean_salary recycling_pct  population_size  \\\n",
              "0                NaN       48922             0           6581.0   \n",
              "1                NaN       23620             3         162444.0   \n",
              "2                NaN       23128             8         313469.0   \n",
              "3                NaN       21386            18         217458.0   \n",
              "4                NaN       20911             6         260317.0   \n",
              "\n",
              "   number_of_jobs  area_size  no_of_houses  borough_flag  \n",
              "0             NaN        NaN           NaN             1  \n",
              "1             NaN        NaN           NaN             1  \n",
              "2             NaN        NaN           NaN             1  \n",
              "3             NaN        NaN           NaN             1  \n",
              "4             NaN        NaN           NaN             1  "
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "OQ8T0tYVQj74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test passed 0\n"
          ]
        }
      ],
      "source": [
        "def drop_duplicates(df):\n",
        "  return housing.drop_duplicates(subset=['area'])\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "# The code below will run and test your code to see if you have returned a series with the correct length and first row\n",
        "actual = drop_duplicates(housing).index[0]\n",
        "expected = 0\n",
        "\n",
        "if actual == expected and len(drop_duplicates(housing)) == 51:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual, \"and length of series should have been 51 but was\", len(drop_duplicates(housing))) "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "3. Sorting_and_cleaning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
